{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "import gymnasium as gym\n",
    "from agents import SACAgent2\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from hydra import compose, initialize\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import wandb\n",
    "import torch as T\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2', continuous=True)\n",
    "n_actions = env.action_space.shape[0] if type(env.action_space) == gym.spaces.box.Box else env.action_space.n\n",
    "env_info = {\"input_dims\":env.observation_space.shape, \"n_actions\": n_actions, \"max_action\": env.action_space.high}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "artifact = api.artifact('tum-adlr-ws22-06/ADLR randomized envs/lunar_lander_model:v131')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   5 of 5 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.\\\\artifacts\\\\lunar_lander_model-v131'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\"conf\"):\n",
    "    cfg = compose(config_name=\"config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SACAgent2(**OmegaConf.to_object(cfg.agent), **OmegaConf.to_object(cfg.training),\n",
    "                      **env_info)\n",
    "agent.load_agent(\".\\\\artifacts\\\\lunar_lander_model-v131\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3228a8334dc64712b89ecd842dd91a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=-10.0, description='g', max=0.0, min=-12.0), FloatSlider(value=0.0, deâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@widgets.interact_manual(g=(-12.0, 0.0), wind_power=(0.0, 20.0), turbulence_power=(0.0, 2.0)\n",
    "                         )\n",
    "def make_video(g=-10, wind_power=0.0, turbulence_power=0.0, plot_every_action=5):\n",
    "    env = gym.make('LunarLander-v2', continuous=True, render_mode='rgb_array', gravity=g , enable_wind=True, wind_power=wind_power, \n",
    "             turbulence_power=turbulence_power)\n",
    "    obs, info = env.reset()\n",
    "    step = 0\n",
    "    while True:\n",
    "        action = agent.action(obs, addNoise=False)\n",
    "        new_obs, reward, done, _, _ = env.step(action)\n",
    "        if step % plot_every_action == 0:\n",
    "            clear_output(wait=True)\n",
    "            plt.imshow( env.render())\n",
    "            plt.show()\n",
    "        step += 1\n",
    "        if done:\n",
    "            break\n",
    "    env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(agent, validation_args, experiment_path, episode, test_env_fabric):\n",
    "    '''\n",
    "    doing all the validation stuff + logging\n",
    "    returns, whether the env is solved\n",
    "    '''\n",
    "    \n",
    "    for evaluation_episode in range(validation_args.eval_eps):\n",
    "        video_path = os.path.join(experiment_path, \"videos\", str(episode))\n",
    "        test_env = test_env_fabric.generate_env()\n",
    "        gravity, enable_wind, wind_power, turbulence_power = test_env.gravity, test_env.enable_wind, test_env.wind_power, test_env.turbulence_power\n",
    "        test_env = RecordVideo(test_env, video_path)\n",
    "        obs, info = test_env.reset()\n",
    "        rewards = 0\n",
    "\n",
    "        for step in range(validation_args.validation_episode_length):\n",
    "\n",
    "            # Get deterministic action\n",
    "            with T.no_grad():\n",
    "                action = agent.action(obs, addNoise=False)\n",
    "                \n",
    "\n",
    "            # Take step in environment\n",
    "            new_obs, reward, done, _, _ = test_env.step(action)\n",
    "\n",
    "            # Update obs\n",
    "            obs = new_obs\n",
    "\n",
    "            # Update rewards\n",
    "            rewards += reward\n",
    "            stop_reward.append(rewards)\n",
    "\n",
    "            # End episode if done\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "    \n",
    "    avg_reward = round(sum(stop_reward) / len(stop_reward), 3)\n",
    "    min_reward = round(min(stop_reward), 3)\n",
    "    \n",
    "    if validation_args.eval_stop_condition == \"avg\":  \n",
    "        stop_reward = avg_reward\n",
    "    elif validation_args.eval_stop_condition == \"min\":\n",
    "        stop_reward = min_reward\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown eval_stop_condition {validation_args.eval_stop_condition}\")\n",
    "    \n",
    "    save_path = os.path.join(experiment_path, \"saves\")\n",
    "    \n",
    "    agent.save_agent(save_path)\n",
    "    \n",
    "    \n",
    "    art = wandb.Artifact(\"lunar_lander_model\", type=\"model\")\n",
    "    for f in os.listdir(save_path):\n",
    "        art.add_file(os.path.join(save_path, f))\n",
    "    wandb.log_artifact(art)\n",
    "    \n",
    "    \n",
    "    print(f\"Episode: {episode} | Average evaluation reward: {avg_reward} | Min evaluation reward: {min_reward} | Agent saved at {save_path}\")\n",
    "    \n",
    "    wandb.log({\"Validation after episode\": episode,  \"Average evaluation reward\": avg_reward,\n",
    "               \"Min evaluation reward\": min_reward})\n",
    "    with open(f\"{experiment_path}/evaluation_rewards.csv\", \"a\") as f:\n",
    "        f.write(f\"{episode}, {stop_reward}\\n\")\n",
    "    try:\n",
    "        if stop_reward > test_env.spec.reward_threshold * 1.1:  # x 1.1 because of small eval_episodes\n",
    "            print(f\"Environment solved after {episode} episodes\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        if stop_reward > -120:\n",
    "            print(f\"Environment solved after {episode} episodes\")\n",
    "            return True\n",
    "    return False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adlr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c91d451bd703414ea6641230092ee74a3e06cec0bad9897d20ace1c483b6d6d8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
